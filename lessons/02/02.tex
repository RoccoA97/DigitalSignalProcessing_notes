\providecommand{\main}{../../main}
\providecommand{\figpath}[1]{\main/../lessons/#1}
\documentclass[../../main/main.tex]{subfiles}



\begin{document}

\chapter{Discrete-Time signals}

\newdate{date}{01}{10}{2020}
\marginpar{ \textbf{Lecture 2.} \\  \displaydate{date}.}

In this Chapter we define more formally the concept of the discrete-time signal and some other properties useful for their description. Historically, discrete-time signals have often been introduced as the discretized version of continuous-time signals, i.e. as the sampled values of analog quantities. For this reason, many of the derivations proceeded within the framework of an underlying continuous-time reality.





\section{Time-Domain representation and basic definitions}
Signals are represented as \textbf{sequences of numbers}, also called \textbf{samples}.
\marginpar{Sample sequence}
Typically, the value of a signal sample is denoted as \( x[n] \), with \( n \) being an integer in the range. So, \( x[n] \) is defined only for \( n \in \mathbb{Z} \) and undefined otherwise, namely for non-integer values of \( n \).

In the introduction we have already presented the common notation for discrete-time signals, namely \( \qty{x[n]} \), with \( - \infty < n < \infty \). Sometimes the numerical values of teh samples are explicitely written inside the curly braces, for example:
\begin{equation}
    \qty{x[n]}
    =
    \qty{\dots, -0.2, {\color{red}2.2}, 1.1, 0.2, -3.7, 2.9, \dots}
    \label{eq:L01_S04_1}
\end{equation}
where the element in red is the sample at time index \( n = 0 \).

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.75\textwidth]{\figpath{02}/02_images/S04_1.pdf}
    \caption{\label{fig:L02_S04_1} Example of sample sequence.}
\end{figure}

In some applications, a discrete-time sequence \( \qty{x[n]} \) may be generated by \textbf{periodically sampling} a continuous-time signal \( x_{a}(t) \) at uniform intervals of time.
\marginpar{Periodic sampling}
An example is showed in Figure \ref{fig:L02_S05_1}. Here, the \( n^{\text{th}} \) sample is given by:
\begin{equation}
    x[n]
    =
    x_{a}(t)_{t = nT}
    =
    x_{a}(nT),
    \qquad
    n = \dots, -2, -1, 0, 1, 2, \dots
    \label{eq:L02_S06_1}
\end{equation}

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.75\textwidth]{\figpath{02}/02_images/S05_1.pdf}
    \caption{\label{fig:L02_S05_1} Example of periodically sampled sequence.}
\end{figure}

The spacing \( T \) between two consecutive samples is called the \textbf{sampling interval} or \textbf{sampling period}.
\marginpar{Sampling period and frequency}
The reciprocal of sampling interval \( T \), denoted as \( F_{T} \), is called the \textbf{sampling frequency}:
\begin{equation}
    F_{T}
    =
    \frac{1}{T}
    \label{eq:L02_S06_2}
\end{equation}

The physical unit of the sampling frequency is ``cycles per second'', or \textbf{Hertz} (Hz), if \( T \) is in seconds. Whether or not the sequence \( \qty{x[n]} \) has been obtained by sampling, the quantity \( x[n] \) is called the \( n^{\text{th}} \) sample of the sequence.
\marginpar{Real and complex sequences}
Moreover, \( \qty{x[n]} \) is called \textbf{real sequence} if the \( n^{\text{th}} \) sample is real for all values of \( n \). Otherwise, \( \qty{x[n]} \) is called \textbf{complex sequence}.

In particular, a complex sequence can be written as:
\begin{equation}
    \qty{x[n]}
    =
    \qty{x_{\mathrm{re}}[n]} + j\qty{x_{\mathrm{im}}[n]}
    \label{eq:L02_S08_1}
\end{equation}
where \( \qty{x_{\mathrm{re}}[n]} \) and \( \qty{x_{\mathrm{im}}[n]} \) are the real and imaginary parts of \( x[n] \). The complex conjugate sequence of \( \qty{x[n]} \) reads:
\begin{equation}
    \qty{x^{*}[n]}
    =
    \qty{x_{\mathrm{re}}[n]} - j\qty{x_{\mathrm{im}}[n]}
    \label{eq:L02_S08_2}
\end{equation}
Note that the braces are often ignored to denote a sequence if there is no ambiguity.

\begin{example}{Real and complex sequences}{}
    \begin{itemize}
        \item \( \qty{x[n]} = \qty{\cos(0.25n)} \) is a real sequence;
        \item \( \qty{y[n]} = \qty{e^{j0.3n}} \) is a complex sequence.
    \end{itemize}
    We can write:
    \begin{equation}
        \qty{y[n]}
        =
        \overbrace{\qty{\cos(0.3n)}}^{\qty{y_{\mathrm{re}}[n]}} +
        j \overbrace{\qty{\sin(0.3n)}}^{\qty{y_{\mathrm{im}}[n]}}
        \label{eq:L02_S09_1}
    \end{equation}

    Then, we consider the complex conjugate of \( \qty{y[n]} \):
    \begin{equation}
        \qty{w[n]}
        =
        \qty{y^{*}[n]}
        =
        \qty{\cos(0.3n)} - j \qty{\sin(0.3n)}
        =
        \qty{e^{-j0.3n}}
        \label{eq:L02_S10_1}
    \end{equation}
\end{example}



\subsection{Categorization of discrete-time signals}
We can have two types of discrete-time signals:
\marginpar{Continuous and discrete-valued signals}
\begin{itemize}
    \item sampled-data signals in which the samples are \textbf{continuous-valued};
    \item digital signals in which the samples are \textbf{discrete-valued}.
\end{itemize}
Signals in a practical digital signal processing system are digital signals obtained by quantizing the sample values wither by rounding or truncation. An example of visualization is showed in Figure \ref{fig:L02_S12_1}.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.75\textwidth]{\figpath{02}/02_images/S12_1.pdf}
    \caption{\label{fig:L02_S12_1} Different way to visualize a signal.}
\end{figure}

\medskip
Again, a discrete-time signal may be a \textbf{finite-length} or an \textbf{infinite-length} sequence.
\marginpar{Finite and infinite-length discrete-time signals}
In the first case, the sequence is defined only for a finite time interval, namely for \( N_{1} \le n \le N_{2} \), where \( - \infty < N_{1} \), \( N_{2} < \infty \) and \( N_{1} \le N_{2} \). The length or duration of the ladder is \( N = N_{2} - N_{1} + 1 \).

A length-\( N \) sequence is often referred to as an \( N \)-point sequence. In general, the length of a finite-length sequence can be increased by using the zero-padding, namely by appending it with zeros. For example:
\begin{equation}
    x_{p}[n]
    =
    \begin{cases}
        n^{2}   &   -3 \le n \le 4  \\
        0       &    5 \le n \le 8
    \end{cases}
    \label{eq:L02_S14_1}
\end{equation}
is a finite-length sequence of length \( 12 \) obtained by zero-padding \( x[n] = n^{2} \), \( -3 \le n \le 4 \), with \( 4 \) zero-valued samples.

\medskip
There is another categorization: a discrete-time signal can be \textbf{right-sided} or \textbf{left-sided}.
\marginpar{Right and left-sided discrete-time signals and (anti)-causal sequences}
A right-sided sequence \( x[n] \) has zero-valued samples for \( n < N_{1} \). Moreover, if \( N_{1} \ge 0 \), a right-sided sequence is called a \textbf{causal sequence}. On the other side, a left-sided sequence \( x[n] \) has zero-valued samples for \( n > N_{2} \) and if \( N_{2} \le 0 \), it is an \textbf{anti-causal sequence}. An example of both the types is showed in Figure \ref{fig:L02_S15_1}.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.4\textwidth]{\figpath{02}/02_images/S16_1.pdf}
    \hspace{1cm}
    \includegraphics[width=0.4\textwidth]{\figpath{02}/02_images/S15_1.pdf}
    \caption{\label{fig:L02_S15_1} Examples of a left-sided sequence (left) and a rigth-sided sequence (right).}
\end{figure}



\subsection{Norm of a discrete-time signal}
When dealing with the analysis of discrete signal, the concept of norm is frequent.
\marginpar{Norm of a discrete-time signal}
In particular, the \( L_{p} \)-norm of a signal reads:
\begin{equation}
    \norm{x}_{p}
    =
    \qty(\sum_{n = -\infty}^{\infty} \abs{x[n]}^{p})^{\frac{1}{p}}
    \label{eq:L02_S17_1}
\end{equation}
where \( p \) is a positive integer. The ladder definition provides an estimate of the size of the signal. The value of \( p \) is typically \( 1 \), \( 2 \) or \( \infty \):
\begin{itemize}
    \item \( p = 1 \): \( \norm{x}_{1} \) is the absolute value of \( \qty{x[n]} \);
    \item \( p = 2 \): \( \norm{x}_{2} \) is the Root-Mean-Squared (RMS) value of \( \qty{x[n]} \);
    \item \( p = \infty \): \( \norm{x}_{\infty} \) is the peak absolute value of \( \qty{x[n]} \), namely \( \norm{x}_{\infty} = \abs{x}_{\mathrm{max}} \).
\end{itemize}
We given an example to understand the application of the norm.

\begin{example}{Norm of a signal}{}
    Let \( \qty{y[n]} \), \( 0 \le n \le N-1 \), be an approximation of \( \qty{x[n]} \), \( 0 \le n \le N-1 \).
    \marginnote{\flushleft\textsl{\small Relative error}}
    An estimate of the relative error is given by the ratio of the \( L_{2} \)-norm of the difference signal and the \( L_{2} \)-norm of \( \qty{x[n]} \):
    \begin{equation}
        E_{\mathrm{rel}}
        =
        \qty(
            \frac{
                \displaystyle \sum_{n=0}^{N-1} \abs{y[n] - x[n]}^{2}
            }{
                \displaystyle \sum_{n=0}^{N-1} \abs{x[n]}^{2}
            }
        )^{\frac{1}{p}}
        \label{eq:L02_S18_1}
    \end{equation}
\end{example}





\section{Operations on sequences}
In order to apply a certain operation on a discrete-time signal we can employ a discrete-time system. If the latter is single-input and single-output, it operates on an input sequence, according to some prescribed rules, and develops another sequence, called the output sequence, wit more desirable properties. This process is schematized in Figure \ref{fig:L02_S19_1}.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.5\textwidth]{\figpath{02}/02_images/S19_1.pdf}
    \caption{\label{fig:L02_S19_1} Scheme of operation on an input sequence, returning an output sequence.}
\end{figure}



\subsection{Basic operations}
In most cases, the operation defining a particular discrete-time system is composed of some basic operations, which we are going to list and study:
\begin{itemize}
    \item \textbf{product} (modulation) operation: \( y[n] = x[n] \cdot w[n] \)\\
    \marginpar{Product operation and windowing}It is employed to form a finite-length sequence from an infinite-length sequence by multiplying the latter with a finite-length sequence called \textbf{window sequence};

    \begin{figure}[!h]
        \centering
        \includegraphics[width=0.3\textwidth]{\figpath{02}/02_images/S20_1.pdf}
        \caption{\label{fig:L02_S20_1} Scheme of product operation.}
    \end{figure}


    \item \textbf{addition} operation: \( y[n] = x[n] + w[n] \)
    \marginpar{Addition operation}

    \begin{figure}[!h]
        \centering
        \includegraphics[width=0.3\textwidth]{\figpath{02}/02_images/S21_1.pdf}
        \caption{\label{fig:L02_S21_1} Scheme of addition operation.}
    \end{figure}


    \item \textbf{multiplication} operation: \( y[n] = A \cdot x[n] \)
    \marginpar{Multiplication operation}

    \begin{figure}[!h]
        \centering
        \includegraphics[width=0.3\textwidth]{\figpath{02}/02_images/S21_2.pdf}
        \caption{\label{fig:L02_S21_2} Scheme of multiplication operation.}
    \end{figure}


    \item \textbf{time-shifting} operation: \( y[n] = x[n-N] \), \( N \in \mathbb{Z} \)\\
    \marginpar{Time-shifting operation}If \( N > 0 \), it is a delaying opeartion. In particular, we have the unit delay with \( y[n] = x[n-1] \). If \( N > 0 \), it is an advance operation, with the particular case of unit advance \( y[n] = x[n+1] \);

    \begin{figure}[!h]
        \centering
        \includegraphics[width=0.3\textwidth]{\figpath{02}/02_images/S22_1.pdf}
        \hspace{1cm}
        \includegraphics[width=0.3\textwidth]{\figpath{02}/02_images/S22_2.pdf}
        \caption{\label{fig:L02_S22_1} Schemes of delaying time-shift (left) and delaying time advance (right) operations.}
    \end{figure}


    \item \textbf{time-reversal} operation: \( y[n] = x[-n] \)
    \marginpar{Time-reversal operation}


    \item \textbf{branching} operation: it provides multiple copies of a sequence.
    \marginpar{Branching operation}

    \begin{figure}[!h]
        \centering
        \includegraphics[width=0.3\textwidth]{\figpath{02}/02_images/S23_1.pdf}
        \caption{\label{fig:L02_S23_1} Scheme of branching operation.}
    \end{figure}
\end{itemize}

When applying these operations, some caution has to be kept. In fact, operations on two or more sequences can be carried out if all sequences involved are of the same length and defined for the same range of the time index \( n \).
However, if the sequences are not of the same length, in some situations, this problem can be circumvented by \textbf{appending zero-valued samples} to the sequence(s) of smaller lengths to make all sequences have the same range of the time index.



\subsection{Ensamble averaging}
This composite operation is a very simple application of the addition operation, useful to improve the quality of measured data corrupted by an additive random noise.
\marginpar{Ensable averaging to improve data quality}
In some cases, actual uncorrupted data vector \( \va{s} \) remains essentially the smae from one mesurement to next, while the additive noise vector is random and not reproducible. Let us denote with \( \va{d}_{i} \) the noise vector corrupting the \( i^{\text{th}} \) measurement of the uncorrupted data vector \( \va{s} \):
\begin{equation}
    \va{x}_{i}
    =
    \va{s} + \va{d}_{i}
    \label{eq:L02_S27_1}
\end{equation}
The average data vector, called the \textbf{ensemble average}, obtained after \( k \) measurements is given by:
\begin{equation}
    \va{x}_{\mathrm{avg}}
    =
    \frac{1}{k} \sum_{i=1}^{k} \va{x}_{i}
    =
    \frac{1}{k} \sum_{i=1}^{k} (\va{s} + \va{d}_{i})
    =
    \va{s} + \frac{1}{k} \sum_{i=1}^{k} \va{d}_{i}
    \label{eq:L02_S28_1}
\end{equation}
For large values of \( k \), \( \va{x}_{\mathrm{avg}} \) is usually a reasonable replica of the desired data vector \( \va{s} \). An example of results obtained by the application of this operation is showed in the plots in Figure \ref{fig:L02_S29_1}.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.75\textwidth]{\figpath{02}/02_images/S29_1.pdf}
    \caption{\label{fig:L02_S29_1} Example of results obtained by the application of the ensable average.}
\end{figure}

Another more general example of ensable average is showed by the scheme in Figure \ref{fig:L02_S30_1}, where the figuring block operation reads:
\begin{equation}
    y[n]
    =
    \alpha_{1}x[n] + \alpha_{2}x[n-1] + \alpha_{3}x[n-2] + \alpha_{4}x[n-3]
    \label{eq:L02_S31_1}
\end{equation}

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.5\textwidth]{\figpath{02}/02_images/S30_1.pdf}
    \caption{\label{fig:L02_S30_1} Ensable average block, performing the operation in Eq. \ref{eq:L02_S31_1}.}
\end{figure}



\subsection{Samping rate alteration}
This is another more complex operation employed to generate a new sequence \( y[n] \) with a sampling rate \( F_{T}' \) higher or lower than that of the sampling rate \( F_{T} \) of a given sequence \( x[n] \).
\marginpar{Sampling rate alteration}
The sampling rate alteration ratio reads:
\begin{equation}
    R
    =
    \frac{F_{T}'}{F_{T}}
    \label{eq:L02_S32_1}
\end{equation}
In particular:
\marginpar{Interpolation and decimation}
\begin{itemize}
    \item if \( R > 1 \), the process is called \textbf{interpolation};
    \item if \( R < 1 \), the process is called \textbf{decimation}.
\end{itemize}

\medskip
\marginpar{Up-sampler}
In the case of \textbf{up-sampling} by an integer factor \( L > 1 \), \( L - 1 \) equidistant zero-valued samples are inserted by the up-sampler between each two consecutive samples of the input sequence \( x[n] \):
\begin{equation}
    x_{u}[n]
    =
    \begin{cases}
        x\qty[\frac{n}{L}]  &   n = 0, \pm L, \pm 2L, \dots \\
        0                   &   \text{otherwise}
    \end{cases}
    \label{eq:L02_S33_1}
\end{equation}
The scheme of this operation is showed in Figure \ref{fig:L02_S33_1}. An example of the results obtained by the application to a certain input sequence are showed in the plots in Figure \ref{fig:L02_S34_1}.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.3\textwidth]{\figpath{02}/02_images/S33_1.pdf}
    \caption{\label{fig:L02_S33_1} Scheme of up-sampling operation.}
\end{figure}

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.75\textwidth]{\figpath{02}/02_images/S34_1.pdf}
    \caption{\label{fig:L02_S34_1} Example of results obtained by the application of the up-sampling.}
\end{figure}

\medskip
\marginpar{Down-sampler}
On the other hand, in the case of \textbf{down-sampling} by an integer factor \( M > 1 \), every \( M^{\text{th}} \) samples of the input sequence are kept and \( M - 1 \) in-between samples are removed:
\begin{equation}
    y[n]
    =
    x[nM]
    \label{eq:L02_S35_1}
\end{equation}
The scheme of this operation is showed in Figure \ref{fig:L02_S35_1}. An example of the results obtained by the application to a certain input sequence are showed in the plots in Figure \ref{fig:L02_S36_1}.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.3\textwidth]{\figpath{02}/02_images/S35_1.pdf}
    \caption{\label{fig:L02_S35_1} Scheme of down-sampling operation.}
\end{figure}

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.75\textwidth]{\figpath{02}/02_images/S36_1.pdf}
    \caption{\label{fig:L02_S36_1} Example of results obtained by the application of the down-sampling.}
\end{figure}





\section{Classification of sequences}
Several classifications of discrete-time sequences are possible, based on certain features of the sequences themselves.

\medskip
\marginpar{Classification based on symmetry}
A first classification is based on the symmetry of the sequence. In fact, we can have \textbf{conjugate-symmteric} sequences, namely satisfying
\begin{equation}
    x[n]
    =
    x^{*}[-n]
    \label{eq:L02_S37_1}
\end{equation}
If \( x[n] \) is real, then it is an \textbf{even sequence}.

Another possibility is a \textbf{conjugate-antisymmetric} sequence, namely satisfying:
\begin{equation}
    x[n]
    =
    - x^{*}[-n]
    \label{eq:L02_S38_1}
\end{equation}
Again, if \( x[n] \) is real, then it is an \textbf{odd} sequence.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.75\textwidth]{\figpath{02}/02_images/S37_1.pdf}
    \includegraphics[width=0.75\textwidth]{\figpath{02}/02_images/S38_1.pdf}
    \caption{\label{fig:L02_S37_1} Example of even (top) and odd (bottom) sequences.}
\end{figure}

It follows from the definition that for a conjugate-symmetric sequence \( \qty{x[n]} \), \( x[0] \) must be a real number. Likewise, for a conjugate antisymmetric sequence \( \qty{y[n]} \), \( y[0] \) must be an imaginary number. Another consequence is that for an odd sequence \( \qty{w[n]} \), \( w[0] = 0 \).

Any complex sequence can be expressed as a sum of its conjugate-symmetric part and its conjugate-antisymmetric part:
\begin{equation}
    x[n]
    =
    x_{\mathrm{cs}}[n] + x_{\mathrm{ca}}[n]
    \label{eq:L02_S40_1}
\end{equation}
where:
\begin{align}
    x_{\mathrm{cs}}[n] &= \frac{1}{2} \qty(x[n] + x^{*}[-n])    \\
    x_{\mathrm{ca}}[n] &= \frac{1}{2} \qty(x[n] - x^{*}[-n])
\end{align}

\begin{example}{Classification based on symmetry}{}
    We consider the length-\( 7 \) sequence defined for \( -3 \le n \le 3 \) and its conjugate and time reversed versions:
    \begin{align}
        \qty{g[n]}
        &=
            \qty{0, 1+j4, -2+j3, {\color{red}4-j2}, -5-j6, -j2, 3}  \\
        \qty{g^{*}[n]}
        &=
            \qty{0, 1-j4, -2-j3, {\color{red}4+j2}, -5+j6,  j2, 3}  \\
        \qty{g^{*}[-n]}
        &=
            \qty{3, j2, -5+j6, {\color{red}4+j2}, -2-j3, 1-j4, 0}
    \end{align}
    Therefore:
    \begin{align}
        \qty{g_{\mathrm{cs}}[n]}
        &=
            \qty{1.5, 0.5+j3, -3.5+j4.5, 4, -3.5-j4.5, 0.5-j3, 1.5} \\
        \qty{g_{\mathrm{ca}}[n]}
        &=
            \qty{-1.5, 0.5+j, 1.5-j1.5, -j2, -1.5-j1.5, -0.5-j, 1.5}
    \end{align}
    It can be easily verified that \( g_{\mathrm{cs}}[n] = g_{\mathrm{cs}}^{*}[-n] \) and \( g_{\mathrm{ca}}[n] = - g_{\mathrm{ca}}^{*}[-n] \).
\end{example}

Now, specializing the previious discussion to real sequences, any of them can be expressed as a sum of its even part and its odd part:
\begin{equation}
    x[n]
    =
    x_{\mathrm{ev}}[n] + x_{\mathrm{od}}[n]
    \label{eq:L02_S43_1}
\end{equation}
where:
\begin{align}
    x_{\mathrm{ev}}[n] &= \frac{1}{2} \qty(x[n] + x[-n])    \\
    x_{\mathrm{od}}[n] &= \frac{1}{2} \qty(x[n] - x[-n])
\end{align}


\medskip
\marginpar{Classification based on periodicity}
A sequence \( \tilde{x}[n] \) satisying \( \tilde{x}[n] = \tilde{x}[n+kN] \) is called a \textbf{periodic sequence} with a period \( N \) where \( N \) is a positive integer and \( k \) is any integer. The smallest value of \( N \) satisfying \( \tilde{x}[n] = \tilde{x}[n+kN] \) is called the \textbf{fundamental period}. A sequence not satisying the periodicity condition is called an \textbf{aperiodic sequence}.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.75\textwidth]{\figpath{02}/02_images/S45_1.pdf}
    \caption{\label{fig:L02_S45_1} Example of periodic sequence.}
\end{figure}


\medskip
Before introducing the classification based on energy and power of the signal, we have to introduce the previous concepts.

The \textbf{total energy} of a sequence \( x[n] \) is defined by:
\marginpar{Definition of energy}
\begin{equation}
    E_{x}
    =
    \sum_{n=-\infty}^{\infty} \abs{x[n]}^{2}
    \label{eq:L02_S46_1}
\end{equation}
An infinite length sequence with finite sample values may or may not have finite energy. On the other hand, a finite length sequence with finite sample values has finite energy.

The \textbf{average power} of an aperiodic sequence is defined by:
\marginpar{Definition of average power}
\begin{equation}
    P_{x}
    =
    \lim_{k \to \infty} \frac{1}{2k+1} \sum_{n=-k}^{k} \abs{x[n]}^{2}
    \label{eq:L02_S47_1}
\end{equation}

We can also define the energy of a sequence \( x[n] \) over a finite interval \( -k \le n \le k \) as:
\begin{equation}
    E_{x,k}
    =
    \sum_{n=-k}^{k} \abs{x[n]}^{2}
    \label{eq:L02_S47_2}
\end{equation}
Then, the averaged power reads:
\begin{equation}
    P_{x}
    =
    \lim_{k \to \infty} \frac{1}{2k+1} E_{x,k}
    \label{eq:L02_S48_1}
\end{equation}

The average power of a periodic sequence \( \tilde{x}[n] \) with a period \( N \) is given by:
\begin{equation}
    P_{x}
    =
    \frac{1}{N} \sum_{n=0}^{N-1} \abs{\tilde{x}[n]}^{2}
    \label{eq:L02_S48_2}
\end{equation}
The average power of an infinite-length sequence may be finite or infinite.

\marginpar{Classification based on energy and power}
We come now to the classification based on the energy and the power:
\begin{itemize}
    \item an infinite energy signal with finite average power is called a \textbf{power signal}. As example, one can think about a periodic sequence, which has a finite average power but infinite energy;
    \item a finite energy signal with zero average power is called an \textbf{energy signal}. As example, one can think about a finite-length sequence which has finite energy but zero average power.
\end{itemize}

\begin{example}{Classification beased on energy and power}{}
    We consider the causal sequence defined by:
    \begin{equation}
        x[n]
        =
        \begin{cases}
            3(-1)^{n}   &   n \ge 0 \\
            0           &   n < 0
        \end{cases}
        \label{eq:L02_S50_1}
    \end{equation}
    Note that \( x[n] \) has infinite energy and its average power is given by:
    \begin{equation}
        P_{x}
        =
        \lim_{k \to \infty} \frac{1}{2k+1} \qty(9 \sum_{n=0}^{k} 1)
        =
        \lim_{k \to \infty} \frac{9(k+1)}{2k+1}
        =
        4.5
        \label{eq:L02_S50_2}
    \end{equation}
\end{example}


\medskip
\marginpar{Bounded sequences}
We move now to other types of classifications. A sequence \( x[n] \) is said to be \textbf{bounded} if:
\begin{equation}
    \abs{x[n]}
    \le
    B_{x}
    <
    \infty
    \label{eq:L02_S51_1}
\end{equation}
For example, the sequence \( x[n] = \cos(0.3\pi n) \) is bounded since the cosine is bounded between \( -1 \) and \( 1 \).

\marginpar{Absolutely summable sequences}
A sequence \( x[n] \) is said to be \textbf{absolutely summable} if:
\begin{equation}
    \sum_{n=-\infty}^{\infty} \abs{x[n]}
    <
    \infty
    \label{eq:L02_S52_1}
\end{equation}

\begin{example}{Absolute summable sequences}{}
    The sequence:
    \begin{equation}
        y[n]
        =
        \begin{cases}
            0.3^{n} &   n \ge 0 \\
            0       &   n < 0
        \end{cases}
        \label{eq:L02_S52_2}
    \end{equation}
    is absolutely summable since:
    \begin{equation}
        \sum_{n=0}^{\infty} \abs{0.3^{n}}
        =
        \frac{1}{1-0.3}
        \approx
        1.42857
        < \infty
        \label{eq:L02_S52_3}
    \end{equation}
\end{example}

\medskip
\marginpar{Square summable sequences}
A sequence \( x[n] \) is said to be \textbf{square summable} if:
\begin{equation}
    \sum_{n=-\infty}^{\infty} \abs{x[n]}^{2}
    <
    \infty
    \label{eq:L02_S53_1}
\end{equation}
For example, the sequence:
\begin{equation}
    h[n]
    =
    \frac{\sin(0.4n)}{\pi n}
    \label{eq:L02_S53_2}
\end{equation}
is square summable but no absolutely summable.





\section{Basic signals}
In this Section, we list some of the most common discrete-time sequences that we find in this field.



\subsection{Unit sample sequence}
The \textbf{unit sample} sequence is defined as:
\marginpar{Unit sample sequence}
\begin{equation}
    \delta[n]
    =
    \begin{cases}
        0   &   n \neq 0    \\
        1   &   n = 0
    \end{cases}
    \label{eq:L02_S54_1}
\end{equation}
and it is visualized in Figure \ref{fig:L02_S54_1}.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.5\textwidth]{\figpath{02}/02_images/S54_1.pdf}
    \caption{\label{fig:L02_S54_1} Unit sample sequence.}
\end{figure}

The importance of this type of sequence stem from the fact that an arbitrar sequence can be represented as a sum of scaled, delayed impulses:
\begin{equation}
    x[n]
    =
    \sum_{k=-\infty}^{\infty} x[k] \delta[n-k]
    \label{eq:L02_S55_1}
\end{equation}



\subsection{Unit step sequence}
The \textbf{unit step} sequence is defined as:
\marginpar{Unit step sequence}
\begin{equation}
    u[n]
    =
    \begin{cases}
        0   &   n \ge 0    \\
        1   &   n < 0
    \end{cases}
    \label{eq:L02_S56_1}
\end{equation}
and it is visualized in Figure \ref{fig:L02_S56_1}.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.5\textwidth]{\figpath{02}/02_images/S56_1.pdf}
    \caption{\label{fig:L02_S56_1} Unit step sequence.}
\end{figure}

The unit step can be expressed in terms of unit samples as:
\begin{equation}
    u[n]
    =
    \sum_{k=0}^{\infty} \delta[n-k]
    \label{eq:L02_S58_2}
\end{equation}



\subsection{Real sinusoidal sequence}
The \textbf{real sinusoidal} sequence is defined as:
\marginpar{Real sinusoidal sequence}
\begin{equation}
    x[n]
    =
    A \cos(\omega_{0}n + \varphi)
    \label{eq:L02_S59_1}
\end{equation}
where \( A \) is the amplitude, \( \omega_{0} \) is the angular frequency, and \( \varphi \) is the phase of \( x[n] \). It is visualized in Figure \ref{fig:L02_S59_1}.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.5\textwidth]{\figpath{02}/02_images/S59_1.pdf}
    \caption{\label{fig:L02_S59_1} Real sinusoidal sequence.}
\end{figure}



\subsection{Exponential sequence}
The \textbf{exponential} sequence is defined as:
\marginpar{Exponential sequence}
\begin{equation}
    x[n]
    =
    A \alpha^{n},
    \qquad
    -\infty < n < \infty
    \label{eq:L02_S60_1}
\end{equation}
where \( A \) and \( \alpha \) are real or complex numbers. If we rewrite:
\begin{align}
    \alpha &= e^{\sigma_{0} + j\omega_{0}}  \\
    A      &= \abs{A} e^{j \varphi}
\end{align}
then we can express:
\begin{equation}
    x[n]
    =
    \abs{A} e^{j \varphi} e^{(\sigma_{0} + j\omega_{0})n}
    =
    x_{\mathrm{re}}[n] + jx_{\mathrm{im}}[n]
    \label{eq:L02_S60_3}
\end{equation}
where:
\begin{align}
    x_{\mathrm{re}}[n] &= \abs{A} e^{\sigma_{0}n} \cos(\omega_{0}n + \varphi)   \\
    x_{\mathrm{im}}[n] &= \abs{A} e^{\sigma_{0}n} \sin(\omega_{0}n + \varphi)
\end{align}
\( x_{\mathrm{re}}[n] \) and \( x_{\mathrm{im}}[n] \) of a complex exponential sequence are real sinusoidal sequences with constant (\( \sigma_{0} = 0 \)), growing (\( \sigma_{0} > 0 \)) and decaying (\( \sigma_{0} < 0 \)) amplitudes for \( n > 0 \). This is visualized in Figure \ref{fig:L02_S61_1}.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.9\textwidth]{\figpath{02}/02_images/S61_1.pdf}
    \caption{\label{fig:L02_S61_1} Real and imaginary part of an exponential sequence.}
\end{figure}

If we consider a real exponential sequence:
\begin{equation}
    x[n]
    =
    A \alpha^{n},
    \qquad
    - \infty < n < \infty
    \label{eq:L02_S62_1}
\end{equation}
where \( A \) and \( \alpha \) are real numbers, we get results similar to the ones in Figure \ref{fig:L02_S62_1}.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.9\textwidth]{\figpath{02}/02_images/S62_1.pdf}
    \caption{\label{fig:L02_S62_1} Amplitude of the real exponential sequence in Eq. \ref{eq:L02_S62_1}, for \( \alpha = 1.2 \) (left) and \( \alpha = 0.9 \) (right).}
\end{figure}

Note that the sinusoidal sequence \( A \cos(\omega_{0}n + \varphi) \) and the complex exponential sequence \( B e^{j\omega_{0}n} \) are periodic sequences of period \( N \) if \( \omega_{0}\pi = 2\pi r \), where \( N \) and \( r \) are positive integers. The smallest value of \( N \) satisfying the latter equality is the fundamental period of the sequence, as we have already seen previously. To verify this fact, we consider:
\begin{align}
    x_{1}[n] &= \cos(\omega_{0}n + \varphi) \\
    x_{2}[n] &= \cos(\omega_{0}(n+N) + \varphi)
\end{align}
Now:
\begin{align}
    x_{2}[n]
    &=
        \cos(\omega_{0}(n+N) + \varphi) \nonumber   \\
    &=
        \cos(\omega_{0}n + \varphi) \cos(\omega_{0}N) - \sin(\omega_{0}n + \varphi) \sin(\omega_{0}N)
\end{align}
which will be equal to \( \cos(\omega_{0}n + \varphi) = x_{1}[n] \) only if \( \sin(\omega_{0}N) = 0 \) and \( \cos(\omega_{0}N) = 1 \).
These two conditions are met if and only if \( \omega_{0}N = 2\pi r \) or \( \frac{2\pi}{\omega_{0}} = \frac{N}{r} \).
If \( \frac{2\pi}{\omega_{0}} \) is a non-integer rational number, then the period will be a multiple of \( \frac{2\pi}{\omega_{0}} \), otherwise the sequence is aperiodic.

From the previous discussion, we can extract two properties:
\begin{itemize}
    \item let us consider \( x[n] = e^{j\omega_{1}n} \) and \( y[n] = e^{j\omega_{2}n} \), with \( 0 \le \omega_{1} \le \pi \) and \( 2\pi k \le \omega_{2} < 2\pi(k+1) \), where \( k \) is any positive integer.
    If \( \omega_{2} = \omega_{1} + 2\pi k \), then \( x[n] = y[n] \). Thus, \( x[n] \) and \( y[n] \) are indistinguishable;
    \item the frequency of oscillation of \( A\cos(\omega_{0}) \) increases as \( \omega_{0} \) increases from \( 0 \) to \( \pi \), and then decreases as \( \omega_{0} \) increases from \( \pi \) to \( 2\pi \).
    Thus frequencies in the neighborhood of \( \omega = 0 \) are called \textbf{low frequencies}, whereas, frequencies in the neighborhood of \( \pi \) are called \textbf{high frequencies}.
\end{itemize}

\end{document}
