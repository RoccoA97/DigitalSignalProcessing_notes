\providecommand{\main}{../../main}
\providecommand{\figpath}[1]{\main/../lessons/#1}
\documentclass[../../main/main.tex]{subfiles}



\begin{document}

\newdate{date}{24}{11}{2020}
\marginpar{ \textbf{Lecture 17.} \\  \displaydate{date}.}

\section{Stability condition}
We move to the discussion about stability, which represents a very important topic. We have already seen that a causal LTI digital filter is BIBO stable if and only if its impulse response \( h[n] \) is absolutely summable, i.e.:
\begin{equation}
    S
    =
    \sum_{n=-\infty}^{\infty} \abs{h[n]}
    < \infty
    \label{eq:L17_S03_1}
\end{equation}
We now develop a stability condition in terms of the pole locations of the transfer function \( H(z) \).

\marginpar{Stability condition in terms of the pole locations}
The ROC of the \( z \)-transform \( H(z) \) of the impulse response sequence \( h[n] \) is defined by values of \( \abs{z} = r \) for which \( h[n]r^{-n} \) is absolutely summable. Thus, if the ROC includes the unit circle \( \abs{z} = 1 \), then the digital filter is stable, and viceversa. In addition, for a stable and causal digital filter for which \( h[n] \) is a right-sided sequence, the ROC will include the unit circle and entire \( z \)-plane including the point \( z = \infty \).

Note that a FIR digital filter with bounded impulse response is always stable. On the other hand, a IIR filter may be unstable if not designed properly.
\marginpar{Problem of coefficients quantization}
In addition, an originally stable IIR filter characterized by infinite precision coefficients may become unstable when coefficients get quantized due to implementation.

\begin{example}{Stability condition}{}
    We consider the causal IIR transfer function:
    \begin{equation}
        H(z)
        =
        \frac{1}{1 - 1.845z^{-1} + 0.850586z^{-2}}
        \label{eq:L17_S06_1}
    \end{equation}
    The plot of the impulse response coefficients is showed below. As can be seen from the plot, the impulse response coefficient \( h[n] \) decays rapidly to zero value as \( n \) increases.

    \begin{center}
        \includegraphics[width=0.75\textwidth]{\figpath{17}/17_images/S07_1.pdf}
    \end{center}

    The absolute summability condition of \( h[n] \) is satisfied. Hence, \( H(z) \) is a stable transfer function. Now, consider the case when the transfer function coefficients are rounded to values with \( 2 \) digits after the decimal point:
    \begin{equation}
        \hat{H}(z)
        =
        \frac{1}{1 - 1.85z^{-1} + 0.85z^{-2}}
        \label{eq:L17_S08_1}
    \end{equation}
    A plot of the impulse response of \( \hat{h}[n] \) is showed below.

    \begin{center}
        \includegraphics[width=0.75\textwidth]{\figpath{17}/17_images/S09_1.pdf}
    \end{center}

    In this case, the impulse coefficient \( \hat{h}[n] \) increases rapidly to a constant value as \( n \) increases. Hence, the absolute summability condition of \( \hat{h}[n] \) is violated. Thus, \( \hat{H}[z] \) is an unstable transfer function.
\end{example}

\marginpar{Stability testing of an IIR transfer function}The stability testing of an IIR transfer function is therefore an important problem. In most cases it is difficult to compute the infinite sum in Eq. \ref{eq:L17_S03_1}. For a causal IIR transfer function, the sum \( S \) can be computed approximately as:
\begin{equation}
    S_{k}
    =
    \sum_{n=0}^{k-1} \abs{h[n]}
    \label{eq:L17_S11_2}
\end{equation}
The partial sum is computed for increasing values of \( k \) until the difference between a series of consecutive values of \( S_{k} \) is smaller than some arbitrarily chosen small number, which is typically \( 10^{-6} \). For a transfer function of very high order this approach may not be satisfactory. An alternate, easy-to-test, stability condition is developed next.

Let us consider the causal IIR digital filter with a rational transfer function \( H(z) \) given by:
\begin{equation}
    H(z)
    =
    \frac{\displaystyle \sum_{k=0}^{M} p_{k}z^{-k}}{\displaystyle \sum_{k=0}^{N} d_{k}z^{-k}}
    \label{eq:L17_S13_1}
\end{equation}
Its impulse response \( \qty{h[n]} \) is a right-sided sequence. The ROC of \( H(z) \) is exterior to a circle going through the pole furthest from \( z = 0 \). But stability requires that \( \qty{h[n]} \) is absolutely summable. This in turn implies that the DTFT \( H(e^{j\omega}) \) of \( \qty{h[n]} \) exists. Now, if the ROC of the \( z \)-transform \( H(z) \) includes the unit circle, then:
\begin{equation}
    H(e^{j\omega})
    =
    \qty[H(z)]_{z=e^{j\omega}}
    \label{eq:L17_S14_1}
\end{equation}
In conclusion, all the poles of a causal stable transfer function \( H(z) \) must be strictly inside the unit circle, as showed in Figure \ref{fig:L17_S15_1}.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.5\textwidth]{\figpath{17}/17_images/S15_1.pdf}
    \caption{\label{fig:L17_S15_1} Stability condition (shaded area).}
\end{figure}

\begin{example}{Stability condition}{}
    The factored form of the previous example transfer function is:
    \begin{equation}
        H(z)
        =
        \frac{1}{1 - 1.845z^{-1} + 0.850586z^{-2}}
        =
        \frac{1}{(1 - 0.902z^{-1})(1 - 0.943z^{-1})}
        \label{eq:L17_S16_1}
    \end{equation}
    which has a real pole at \( z = 0.902 \) and a real pole at \( z = 0.943 \). Since both ples are inside the unit circle, \( H(z) \) is BIBO stable.

    On the other hand, the factored form of \( \hat{H}(z) \) is:
    \begin{equation}
        \hat{H}(z)
        =
        \frac{1}{1 - 1.85z^{-1} + 0.85z^{-2}}
        =
        \frac{1}{(1 - z^{-1})(1 - 0.85z^{-1})}
        \label{eq:L17_S17_1}
    \end{equation}
    which has a real pole on the unit circle at \( z = 1 \) and the other pole inside the unit circle. Since not both the poles are inside the unit circle, \( \hat{H}(z) \) is unstable.
\end{example}










\chapter{Filter design}

In the previous Chapters we have seen an overview on both the nature of discrete-time signals and on the tools that can be used to analyze their properties. Now, we can focus on the study of the fundamental building blocks of any Digital Signal Processing system and on the design of more complex composite systems. We will go on by studying several examples to understand how the theory can be applied in practice.





\section{Preliminary concepts and definitions}
Before starting with the discussion of filter design, we have to introduce and recap some other useful concepts for the following discussion.



\subsection{Phase delay}
If the input \( x[n] \) to an LTI system \( H(e^{j\omega}) \) is a sinusoidal signal of frequency \( \omega_{0} \), i.e.:
\begin{equation}
    x[n]
    =
    A\cos\qty(\omega_{0}n + \varphi),
    \qquad
    - \infty < n < \infty
    \label{eq:L17_S18_1}
\end{equation}
then the output \( y[n] \) is also a sinusoidal signal of the same frequency \( \omega_{0} \), but lagging in phase by \( \theta(\omega_{0}) \) radians:
\begin{equation}
    y[n]
    =
    A \abs{H(e^{j\omega_{0}})} \cos\qty(\omega_{0}n + \theta(\omega_{0}) + \varphi),
    \qquad
    - \infty < n < \infty
    \label{eq:L17_S18_2}
\end{equation}
We can rewrite the output expression as:
\begin{equation}
    y[n]
    =
    A \abs{H(e^{j\omega_{0}})} \cos\qty(\omega_{0}(n-\tau_{p}(\omega_{0}) + \varphi))
    \label{eq:L17_S19_1}
\end{equation}
where:
\marginpar{Phase delay}
\begin{equation}
    \tau_{p}(\omega_{0})
    =
    - \frac{\theta(\omega_{0}))}{\omega_{0}}
    \label{eq:L17_S19_2}
\end{equation}
is called the \textbf{phase delay}. The minus sign in front indicates a phase lag. Thus, the output \( y[n] \) is a \textbf{time-delayed version} of the input \( x[n] \). In general, \( y[n] \) will not be a delayed replica of \( x[n] \) unless the phase delay \( \tau_{p}(\omega_{0}) \) is an integer.



\subsection{Group delay}
When the input is composed of many sinusoidal components with different frequencies that are not harmonically related, each component will go through different phase delays. In this case, the signal delay is determined using the \textbf{group delay}, defined by:
\marginpar{Group delay}
\begin{equation}
    \tau_{g}(\omega)
    =
    - \dv{\theta(\omega)}{\omega}
    \label{eq:L17_S21_1}
\end{equation}
In defining the group delay, it is assumed that the phase function is unwrapped so that its derivatives exist.

\begin{example}{Phase and group delay}{}
    The phase function of the FIR filter:
    \begin{equation}
        y[n]
        =
        \alpha x[n] + \beta x[n-1] + \alpha x[n-2]
        \label{eq:L17_S22_1}
    \end{equation}
    is:
    \begin{equation}
        \theta(\omega)
        =
        - \omega
        \label{eq:L17_S22_2}
    \end{equation}
    Hence, its group delay is given by \( \tau_{g}(\omega) = 1 \).
\end{example}



\subsection{Types of transfer function}
The time-domain classification of an LTI digital transfer function sequence is based on the length of its impulse response. We can have:
\marginpar{Classification on the length of the impulse response}
\begin{itemize}
    \item \textbf{Finite Impulse Response (FIR)} transfer functions;
    \item \textbf{Infinite Impulse Response (IIR)} transfer functions.
\end{itemize}
In the case of digital transfer functions with frequency-selective frequency responses, there are two other types of classifications:
\marginpar{Other classifications}
\begin{itemize}
    \item a classification based on the \textbf{shape of the magnitude function} \( \abs{H(e^{j\omega})} \);
    \item a classification based on the \textbf{form of the phase function} \( \theta(\omega) \).
\end{itemize}
One common classification is based on an ideal magnitude response. A digital filter designed to pass signal components of certain frequencies without distortion should have a frequency response equal to one at these frequencies, and should have a frequency response equal to zero at all other frequencies.


\medskip
We focus now to the case of ideal filters. In general, the range of frequencies where the frequency response takes the value of one is called the \textbf{passband}.
\marginpar{Passband and stopband}The range of frequencies where the frequency response takes the value of zero is called the \textbf{stopband}. In this context, the frequency responses of the four popular types of ideal digital filters with real impulse response coefficients are showed in Figure \ref{fig:L17_S27_1}.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.75\textwidth]{\figpath{17}/17_images/S27_1.pdf}
    \caption{\label{fig:L17_S27_1} Frequency responses of the four popular types of ideal digital filters with real impulse response coefficients.}
\end{figure}

In particular, the passband and stopband of those filters are listed in Table \ref{tab:L17_S28_1}. The frequencies \( \omega_{c} \), \( \omega_{c_{1}} \) and \( \omega_{c_{2}} \) are called the \textbf{cutoff frequencies}.
\marginpar{Cutoff frequency}An ideal filter has a magnitude response equal to one in the passband and zero in the stopband, and has a zero phase everywhere.

\begin{table}[!h]
    \centering
    \begin{tabular}{ccc}
        \toprule
        Type    &   Passband    &   Stopband    \\
        \midrule
        Lowpass &   \( 0 \le \omega \le \omega_{c} \)   &   \( \omega_{c} < \omega \le \pi \)   \\
        Highpass &   \( \omega_{c} \le \omega \le \pi \)   &   \( 0 \le \omega < \omega_{c} \)   \\
        Bandpass &   \( \omega_{c_{1}} \le \omega \le \omega_{c_{2}} \)   &   \( 0 \le \omega < \omega_{c_{1}} \) and \( \omega_{c_{2}} < \omega \le \pi \)   \\
        Stopband &   \( 0 \le \omega \le \omega_{c_{1}} \) and \( \omega_{c_{2}} \le \omega \le \pi \)  &   \( \omega_{c_{1}} < \omega < \omega_{c_{2}} \)  \\
        \bottomrule
    \end{tabular}
    \caption{Passband and stopband of the four popular types of ideal digital filters.}
    \label{tab:L17_S28_1}
\end{table}

Let us pickle an example. Earlier in the course we derived the inverse DTFT of the frequency response \( H_{LP}(e^{j\omega}) \) of the ideal lowpass filter:
\begin{equation}
    h_{LP}[n]
    =
    \frac{\sin\qty(\omega_{c}n)}{\pi n},
    \qquad
    -\infty < n < \infty
    \label{eq:L17_S30_1}
\end{equation}
We have also showed that the impulse response in Eq. \ref{eq:L17_S30_1} is not absolutely summable, and hence, the corresponding transfer function is not BIBO stable. Also, \( h_{LP}[n] \) is not causal and is of doubly infinite length. The remaining three ideal filters are also characterized by doubly infinite, non-causal impulse responses and are not absolutely summable. Thus, the ideal filters with the ideal ``brick wall'' frequency responses cannot be realized with finite dimensional LTI filter.

To develop stable and realizable transfer functions, the ideal frequency response specifications are relaxed by including a \textbf{transition band}\marginpar{Transition band between passband and stopband} between the passband and the stopband. This permits the magnitude response to decay slowly from its maximum value in the passband to the zero value in the stopband. Moreover, the magnitude response is allowed to vary by a small amount both in the passband and the stopband. Typical magnitude response specifications of a lowpass filter are showed in Figure \ref{fig:L17_S33_1}.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.5\textwidth]{\figpath{17}/17_images/S33_1.pdf}
    \caption{\label{fig:L17_S33_1} Typical magnitude response specifications of a lowpass filter.}
\end{figure}



\subsection{Bounded real transfer function}
A causal stable real-coefficient transfer function \( H(z) \) is defined as a \textbf{bounded real (BR) transfer function} if:
\marginpar{Bounded real transfer function}
\begin{equation}
    \abs{H(e^{j\omega})}
    \le
    1
    \qquad
    \forall \omega
    \label{eq:L17_S34_1}
\end{equation}
Now, let \( x[n] \) and \( y[n] \) denote, respectively, the input and output of a digital filter characterized by a BR transfer function \( H(z) \) with \( X(e^{j\omega}) \) and \( Y(e^{j\omega}) \) denoting their DTFTs. Then, the condition in Eq. \ref{eq:L17_S34_1} implies that:
\begin{equation}
    \abs{Y(e^{j\omega})}^2
    \le
    \abs{X(e^{k\omega})}^2
    \label{eq:L17_S35_1}
\end{equation}
Integrating Eq. \ref{eq:L17_S35_1} from \( - \pi \) to \( \pi \) and applying Parseval's relation, we get:
\begin{equation}
    \sum_{n=-\infty}^{\infty} y[n]^2
    \le
    \sum_{n=-\infty}^{\infty} x[n]^2
    \label{eq:L17_S35_2}
\end{equation}
Thus, for all finite-energy inputs, the output energy is less than or equal to the input energy implying that a digital filter characterized by a BR transfer function can be viewed as a \textbf{passive structure}.
If \( \abs{H(e^{j\omega})} = 1 \), then the output energy is equal to the input energy, and such a digital filter is therefore a \textbf{lossless system}.

\marginpar{Lossless bounded real transfer function}
A causal stable real-coefficient transfer function \( H(z) \) with \( \abs{H(e^{j\omega})} = 1 \) is thus called a \textbf{lossless bounded real (LBR) transfer function}.
The BR and LBR transfer functions are the keys to the realization of digital filters with low coefficient sensitivity.

\begin{example}{Bounded real transfer function}{}
    Consider the causal stable IIR transfer function:
    \begin{equation}
        H(z)
        =
        \frac{k}{1 - \alpha z^{-1}},
        \qquad
        0 < \abs{\alpha} < 1
        \label{eq:L17_S38_1}
    \end{equation}
    where \( k \) is a real constant. Its square-magnitude function is given by:
    \begin{equation}
        \abs{H(e^{j\omega})}^2
        =
        \qty[H(z)H(z^{-1})]_{z=e^{j\omega}}
        =
        \frac{k^2}{(1+\alpha^2) - 2\alpha \cos\omega}
        \label{eq:L17_S38_2}
    \end{equation}
    The maximum value of \( \abs{H(e^{j\omega})}^2 \) is obtained when \( 2\alpha \cos\omega \) in the denominator is a maximum and the minimum value is obtained when \( 2\alpha \cos\omega \) is a minimum. For \( \alpha > 0 \), the maximum value of \( 2\alpha \cos\omega \) is equal to \( 2\alpha \) at \( \omega = 0 \), and the minimum value is \( -2\alpha \) at \( \omega = \pi \).

    Thus, for \( \alpha > 0 \), the maximum value of \( \abs{H(e^{j\omega})}^2 \) is equal to \( \frac{k^{2}}{(1-\alpha)^2} \) at \( \omega = 0 \) and the minimum value is equal to \( \frac{k^{2}}{(1+\alpha)^2} \) at \( \omega = \pi \).

    On the other hand, for \( \alpha < 0 \), the maximum value of \( 2\alpha \cos\omega \) is equal to \( -2\alpha \) at \( \omega = \pi \) and the minimum value is equal to \( 2\alpha \) at \( \omega = 0 \).
    Here, the maximum value of \( \abs{H(e^{j\omega})}^{2} \) is equal to \( \frac{k^{2}}{(1-\alpha)^2} \) at \( \omega = \pi \), and the minimum value is equal to \( \frac{k^{2}}{(1+\alpha)^2} \) at \( \omega = 0 \).
    Hence, the maximum value can be made equal to \( 1 \) by choosing \( k = \pm (1-\alpha) \), in which case the minimum value becomes \( \frac{(1-\alpha)^2}{(1+\alpha)^2} \).

    Hence:
    \begin{equation}
        H(z)
        =
        \frac{k}{1 - \alpha z^{-1}},
        \qquad
        0 < \abs{\alpha} < 1
        \label{eq:L17_S42_1}
    \end{equation}
    is a BR function for \( k = \pm (1-\alpha) \). Plots of the magnitude function for \( \alpha = \pm 0.5 \) with values of \( k \) chosen to make \( H(z) \) a BR function are showed below.

    \begin{center}
        \includegraphics[width=0.5\textwidth]{\figpath{17}/17_images/S43_1.pdf}

        \includegraphics[width=0.5\textwidth]{\figpath{17}/17_images/S43_2.pdf}
    \end{center}
\end{example}



\subsection{Allpass transfer function}
\marginpar{Allpass transfer function definition}
\begin{definition}{Allpass transfer function}{}
    An IIR transfer function \( A(z) \) with unity magnitude response for all frequencies, i.e.:
    \begin{equation}
        \abs{A(e^{j\omega})}^{2}
        =
        1
        \qquad
        \forall \omega
        \label{eq:L17_S44_1}
    \end{equation}
    is called an \textbf{allpass transfer function}.
\end{definition}

An \( M^{\text{th}} \) order causal real-coefficient allpass transfer function is of the form:
\begin{equation}
    A_{M}(z)
    =
    \pm \frac{d_{M} + d_{M-1}z^{-1} + \dots + d_{1}z^{-M+1} + z^{-M}}{1 + d_{1}z^{-1} + \dots d_{M-1}z^{-M+1} + d_{M}z^{-M}}
    \label{eq:L17_S44_2}
\end{equation}
If we denote the denominator polynomials of \( A_{M}(z) \) as \( D_{M}(z) \):
\begin{equation}
    D_{M}(z)
    =
    1 + d_{1}z^{-1} + \dots + d_{M-1}z^{-M+1} + d_{M}z^{-M}
    \label{eq:L17_S45_1}
\end{equation}
then it follows that \( A_{M}(z) \) can be written as:
\begin{equation}
    A_{M}(z)
    =
    \pm \frac{z^{-M}D_{M}(z^{-1})}{D_{M}(z)}
    \label{eq:L17_S45_2}
\end{equation}
Note that if \( z = re^{j\omega} \) is a pole of a real coefficient allpass transfer function, then it has a zero at \( z = \frac{1}{r} e^{-j \varphi} \).

The numerator of a real-coefficient allpass transfer function is said to be the \textbf{mirror-image polynomial} of the denominator, and vice versa.
\marginpar{Mirror-image polynomial and symmetry}We shall use the notation \( \widetilde{D}_{M}(z) \) to denote the mirror-image polynomial of a degree-\( M \) polynomial \( D_{M}(z) \), i.e.:
\begin{equation}
    \widetilde{D}_{M}(z)
    =
    z^{-M} D_{M}(z^{-1})
    \label{eq:L17_S46_1}
\end{equation}
The expression in Eq. \ref{eq:L17_S45_2} implies that the poles and zeros of a real-coefficient allpass function exhibit \textbf{mirror-image symmetry} in the \( z \)-plane.

\begin{example}{Allpass transfer function}{}
    \begin{equation}
        A_{3}(z)
        \frac{-0.2 + 0.81z^{-1} + 0.4z^{-2} + z^{-3}}{1 + 0.4z^{-1} + 0.18z^{-2} - 0.2z^{-3}}
        \label{eq:L17_S47_2}
    \end{equation}

    \begin{center}
        \includegraphics[width=0.5\textwidth]{\figpath{17}/17_images/S47_1.pdf}
    \end{center}
\end{example}

To show that \( \abs{A_{M}(e^{j\omega})}^{2} = 1 \), we observe that:
\begin{equation}
    A_{M}(z^{-1})
    =
    \pm \frac{z^{M} D_{M}(z)}{D_{M}(z^{-1})}
    \label{eq:L17_S48_1}
\end{equation}
Therefore:
\begin{equation}
    A_{M}(z) A_{M}(z^{-1})
    =
    \frac{z^{-M}D_{M}(z^{-1})}{D_{M}(z)} \frac{z^{M} D_{M}(z)}{D_{M}(z^{-1})}
    \label{eq:L17_S48_2}
\end{equation}
Hence:
\begin{equation}
    \abs{A_{M}(e^{j\omega})}^2
    =
    \qty[A_{M}(z) A_{M}(z^{-1})]_{z=e^{j\omega}}
    =
    1
    \label{eq:L17_S48_3}
\end{equation}
Now, the poles of a causal stable transfer function must lie inside the unit circle in the \( z \)-plane. Hence, all the zeros of a causal stable allpass transfer function must lie outside the unit circle in a mirror-image symmetry with its poles situated inside the unit circle.

\begin{example}{Allpass transfer function}{}
    Consider the \( 3^{\text{rd}} \) order allpass function:
    \begin{equation}
        A_{3}(z)
        =
        \frac{-0.2 + 0.18z^{-1} + 0.4z^{-2} + z^{-3}}{1 + 0.4z^{-1} + 0.18z^{-2} - 0.2z^{-3}}
        \label{eq:L17_S50_1}
    \end{equation}

    The principal value of phase is showed in the plot below. Note the discontinuity by the amount of \( 2\pi \) in the phase \( \theta(\omega) \).

    \begin{center}
        \includegraphics[width=0.5\textwidth]{\figpath{17}/17_images/S50_1.pdf}
    \end{center}

    If we unwrap the phase by removing the discontinuity, we arrive at the unwrapped phase function \( \theta_{c}(\omega) \) indicated in the plot below. Note that the unwrapped phase function is a continuous function of \( \omega \).

    \begin{center}
        \includegraphics[width=0.5\textwidth]{\figpath{17}/17_images/S51_1.pdf}
    \end{center}
\end{example}


\medskip
\marginpar{Properties of allpass transfer function}
We list now the properties of allpass transfer function:
\begin{itemize}
    \item a causal stable real-coefficient allpass transfer function is a lossless bounded real (LBR) function or, equivalently, a causal stable allpass filter is a lossless structure;

    \item the magnitude function of a stable allpass function \( A(z) \) satisfies:
    \marginpar{Magnitude function}
    \begin{equation}
        \abs{A(z)}
        \begin{cases}
            <1  &   \abs{z} > 1 \\
            =1  &   \abs{z} = 1 \\
            >1  &   \abs{z} < 1
        \end{cases}
        \label{eq:L17_S52_1}
    \end{equation}

    \item let \( \tau(\omega) \) denote the group delay function of an allpass filter \( A(z) \):
    \marginpar{Group delay}
    \begin{equation}
        \tau(\omega)
        =
        - \dv{}{\omega} \qty[\theta_{c}(\omega)]
        \label{eq:L17_S52_2}
    \end{equation}
\end{itemize}

The unwrapped phase function \( \theta_{c}(\omega) \) of a stable allpass function is a monotonically decreasing function of \( \omega \) so that \( \tau(\omega) \) is everywhere positive in the range \( 0 < \omega < \pi \). The group delay of an \( M^{\text{th}} \) order stable real-coefficient allpass transfer function satisfies:
\begin{equation}
    \int_{0}^{\pi} \tau(\omega) \d{\omega}
    =
    M\pi
    \label{eq:L17_S53_1}
\end{equation}

\marginpar{Delay equalizer application}
A simple but often used application of an allpass filter is as a \textbf{delay equalizer}.
Let \( G(z) \) be the transfer function of a digital filter designed to meet a prescribed magnitude response. The non-linear phase response of \( G(z) \) can be corrected by cascading it with an allpass filter \( A(z) \) so that the overall cascade has a constant group delay in the band of interest.
Since \( \abs{A_{M}(e^{j\omega})} = 1 \), we have:
\begin{equation}
    \abs{G(e^{j\omega}) A(e^{j\omega})}
    =
    \abs{G(e^{j\omega})}
    \label{eq:L17_S55_1}
\end{equation}
The overall group delay is given by the sum of the group delays of \( G(z) \) and \( A(z) \).



\subsection{Phase characteristics}
\marginpar{Classification on phase characteristics}
A second classification of a transfer function is with respect to its \textbf{phase characteristics}. In many applications, it is necessary that the digital filter designed does not distort the phase of the input signal components for frequencies in the passband.
One way to avoid any phase distortion is to make the frequency response of the filter real and non-negative, i.e., to design the filter with a \textbf{zero-phase characteristic}. However, it is not possible to design a causal digital filter with a zero phase.

For non-real-time processing of real-valued input signals of finite length, \marginpar{Zero-phase filtering}\textbf{zero-phase filtering} can be very simply implemented by relaxing the causality requirement. One zero-phase filtering scheme is sketched in Figure \ref{fig:L17_S58_1}. It is easy to verify the ladder in the frequency domain.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.75\textwidth]{\figpath{17}/17_images/S58_1.pdf}
    \caption{\label{fig:L17_S58_1} A possible zero-phase filtering scheme.}
\end{figure}

Let \( X(e^{j\omega}) \), \( V(e^{j\omega}) \), \( U(e^{j\omega}) \), \( W(e^{j\omega}) \) and \( Y(e^{j\omega}) \) denote the DTFTs of \( x[n] \), \( v[n] \), \( u[n] \), \( w[n] \) and \( y[n] \), respectively. Making use of the symmetry relations, we arrive at the relations between various DTFTs:
\begin{align}
    V(e^{j\omega})  &=  H(e^{j\omega}) X(e^{j\omega})   \\
    W(e^{j\omega})  &=  H(e^{j\omega}) U(e^{j\omega})   \\
    U(e^{j\omega})  &=  V^{*}(e^{j\omega})              \\
    Y(e^{j\omega})  &=  W^{*}(e^{j\omega})
\end{align}
Combining the above equations we get:
\begin{align}
    Y(e^{j\omega})
    &=
        W^{*}(e^{j\omega})  \nonumber   \\
    &=
        H^{*}(e^{j\omega}) U^{*}(e^{j\omega})   \nonumber   \\
    &=
        H^{*}(e^{j\omega}) V(e^{j\omega})   \nonumber   \\
    &=
        H^{*}(e^{j\omega}) H(e^{j\omega}) X(e^{j\omega})   \nonumber   \\
    &=
        \abs{H(e^{j\omega})}^{2} X(e^{j\omega})
\end{align}

The most general type of a filter with a linear phase has a frequency response given by:
\begin{equation}
    H(e^{j\omega})
    =
    e^{-j\omega D}
    \label{eq:L17_S61_1}
\end{equation}
which has a linear phase from \( \omega = 0 \) to \( \omega = 2\pi \). Note also that:
\begin{equation}
    \abs{H(e^{j\omega})} = 1
    \label{eq:L17_S61_2}
\end{equation}
and:
\begin{equation}
    \tau(\omega)
    =
    - \dv{}{\omega} \qty[\theta_{c}(\omega)]
    =
    D
    \label{eq:L17_S61_3}
\end{equation}
The output \( y[n] \) of this filter to an input \( x[n] = Ae^{j\omega n} \) is then given by:
\begin{equation}
    y[n]
    =
    Ae^{-j\omega D} e^{j\omega n}
    =
    Ae^{j\omega(n-D)}
    \label{eq:L17_S62_1}
\end{equation}
If \( x_{a}(t) \) and \( y_{a}(t) \) represent the continuous-time signals whose sampled versions, sampled at \( t = nT \), are \( x[n] \) and \( y[n] \) given above, then the delay between \( x_{a}(t) \) and \( y_{a}(t) \) is precisely the group delay of amount \( D \).
If \( D \) is an integer, then \( y[n] \) is identical to \( x[n] \), but delayed by \( D \) samples. If \( D \) is not an integer, \( y[n] \), being delayed by a fractional part, is not identical to \( x[n] \). In the latter case, the waveform of the underlying continuous-time output is identical to the waveform of the underlying continuous-time input and delayed \( D \) units of time.

If it is desired to pass input signal components in a certain frequency range undistorted in both magnitude and phase, then the transfer function should exhibit a unity magnitude response and a linear-phase response in the band of interest. In Figure \ref{fig:L17_S65_1} the frequency response of a lowpass filter with a linear-phase characteristic in the passband is showed. Since the signal components in the stopband are blocked, the phase response in the stopband can be of any shape.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.3\textwidth]{\figpath{17}/17_images/S65_1.pdf}
    \caption{\label{fig:L17_S65_1} Frequency response of a lowpass filter with a linear-phase characteristic in the passband.}
\end{figure}

\begin{example}{Linear-phase transfer function}{}
    We determine now the impulse response of an ideal lowpass filter with a linear phase response:
    \begin{equation}
        H_{LP}(e^{j\omega})
        =
        \begin{cases}
            e^{-j\omega n_{0}}  &   0 < \abs{\omega} < \omega_{c}   \\
            0   &   \omega_{c} \le \abs{\omega} \le \pi
        \end{cases}
        \label{eq:L17_S66_1}
    \end{equation}
    Applying the frequency-shifting property of the DTFT to the impulse response of an ideal zero-phase lowpass filter we arrive at:
    \begin{equation}
        h_{LP}[n]
        =
        \frac{\sin\qty(\omega(n-n_{0}))}{\pi (n-n_{0})}
        \qquad
        -\infty < n < \infty
        \label{eq:L17_S67_1}
    \end{equation}
    As before, the above filter is noncausal and of doubly infinite length, and hence, unrealizable. By truncating the impulse response to a finite number of terms, a realizable FIR approximation to the ideal lowpass filter can be developed. The truncated approximation may or may not exhibit linear phase, depending on the value of \( n_{0} \) chosen.

    If we choose \( n_{0} = \frac{N}{2} \) with \( N \) a positive integer, the truncated and shifted approximation:
    \begin{equation}
        \hat{h}_{LP}[n]
        =
        \frac{\displaystyle \sin\qty(\omega_{c}\qty(n-\frac{N}{2}))}{\displaystyle \pi \qty(n-\frac{N}{2})}
        \qquad
        0 \le n \le N
        \label{eq:L17_S69_1}
    \end{equation}
    will be a length \( N+1 \) causal linear-phase FIR filter. In the plot below the filter coefficients are showed. They are obtained using the function \( \operatorname{sinc} \) for two different values of \( N \).

    \begin{center}
        \includegraphics[width=0.9\textwidth]{\figpath{17}/17_images/S70_1.pdf}
    \end{center}

    Because of the symmetry of the impulse response coefficients as indicated in the two plots, the frequency response of the truncated approximation can be expressed as:
    \marginnote{\flushleft\textsl{\small Zero-phase response or amplitude response}}
    \begin{equation}
        \hat{H}_{LP}(e^{j\omega})
        =
        \sum_{n=0}^{N} \hat{h}_{LP}[n] e^{-j\omega n}
        =
        e^{-j\omega \frac{N}{2}} \widetilde{H}_{LP}(\omega)
        \label{eq:L17_S71_1}
    \end{equation}
    where \( \widetilde{H}_{LP}(\omega) \), called the \textbf{zero-phase response} or \textbf{amplitude response}, is a real function of \( \omega \).
\end{example}

\end{document}
